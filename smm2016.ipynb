{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4bffcdd8-c3a5-456e-8289-23678137d058"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, Image, Markdown\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(\"microTC\")\n",
    "from microtc.textmodel import TextModel\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "from graphviz import Digraph\n",
    "dot = Digraph(comment='microtc pipeline', format=\"png\")\n",
    "# dot.engine = 'circo'\n",
    "dot.graph_attr['rankdir'] = 'LR'\n",
    "dot.node('i', '', style=\"invis\")\n",
    "dot.node('n', 'NormalizaciÃ³n')\n",
    "dot.node('t', 'TokenizaciÃ³n')\n",
    "dot.node('w', 'Pesado')\n",
    "dot.node('c', 'ClasificaciÃ³n')\n",
    "dot.node('o', '', style=\"invis\")\n",
    "\n",
    "dot.edge('i', 'n', label=\"texto entrada\")\n",
    "dot.edge('n', 't', label=\"texto normalizado\")\n",
    "dot.edge('t', 'w', label=\"bolsa de palabras\")\n",
    "dot.edge('w', 'c', label=\"vector con pesos\")\n",
    "dot.edge('c', 'o', label=\"clase\")\n",
    "\n",
    "pipeline = dot.render(\"fig-pipeline\", view=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c3871447-3727-48a1-b4ff-887ba971be91"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ClasificaciÃ³n de texto #\n",
    "## Un enfoque basado en $\\mu TC$ ##\n",
    "\n",
    "\n",
    "**Seminario de la Sociedad MatemÃ¡tica Mexicana SMM 2016**\n",
    "\n",
    "\n",
    "<div>\n",
    "    Eric Sadit TÃ©llez Avila INFOTEC \n",
    "    <estellezav@conacyt.mx> <br/>\n",
    "       CONACyT -- INFOTEC\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2a1c3de4-2d92-45aa-9a15-8102f294f125"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda #\n",
    "- Â¿QuÃ© es $\\mu TC$\n",
    "- Â¿En quÃ© consiste la tarea de clasificaciÃ³n de texto?\n",
    "- Â¿CÃ³mo esta compuesto $\\mu TC$?\n",
    "- Estado del arte\n",
    "- CÃ³mo se compara $\\mu TC$ con el estado del arte\n",
    "- QuÃ© falta en $\\mu TC$\n",
    "- Ejemplos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "02bc8966-186d-4b47-9cf1-2ad9246d0491"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CategorizaciÃ³n de texto ##\n",
    "El problema consiste en, dado un texto $d$, determinar la(s) categorÃ­a(s) a la que pertenece en un conjunto $C$ de categorias, previamente conocido.\n",
    "\n",
    "MÃ¡s formalmente:\n",
    "\n",
    "Dado un conjunto de categorias $\\cal{C} = \\{c_1, ..., c_m\\}$, determinar el subconjunto de categorias\n",
    "$C_d \\in \\wp(\\cal{C})$ a las que pertenece $d$. \n",
    "\n",
    "Notese que $C_t$ puede ser vacio o $\\cal{C}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "88cc9133-1951-4231-b1d3-a58428599fcd"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ClasificaciÃ³n de texto ##\n",
    "La _clasificaciÃ³n_ de texto es una especializaciÃ³n del problema de categorizaciÃ³n, donde $|C_d| = 1$, esto es $d$ solo puede ser asignado a una categorÃ­a.\n",
    "\n",
    "Es un problema de interÃ©s en la industria y la acÃ¡demia, con aplicaciones variadas a distintas Ã¡reas del conocimiento.\n",
    "\n",
    "- AnÃ¡lisis de sentimiento\n",
    "- DeterminaciÃ³n de autorÃ­a, e.g., gÃ©nero, edad, estilo, etc.\n",
    "- DetecciÃ³n de spam\n",
    "- CategorizaciÃ³n de noticias\n",
    "- ClasificaciÃ³n de idioma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "976a69bb-2f5d-4f78-9f9f-1fc016f635e5"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Procesamiento de Lenguaje Natural #\n",
    "\n",
    "\n",
    "Un documento $d=s_1\\cdots s_n$ es simplemente la concatenaciÃ³n de sÃ­mbolos $s \\in \\Sigma$. Donde, $\\Sigma$ es un _alfabeto_ de tamaÃ±o $\\sigma = |\\Sigma|$\n",
    "\n",
    "Notese quÃ© el nÃºmero de textos posibles de tamaÃ±o $n$ es $\\sigma^n$, por ejemplo, limitados a texto en inglÃ©s en Twitter se tienen\n",
    "    $$ 26^{140} \\simeq 1.248 \\times 10^{198} $$\n",
    "\n",
    "Sin emabargo, en lenguaje natural, este nÃºmero no suele ser tan grande:\n",
    "  - existen reglas sobre que sÃ­mbolos se pueden unir\n",
    "  - mÃ¡s aÃºn, hay nociÃ³n de _terminos_ o _palabras_, i.e., _morfologÃ­a_\n",
    "  - tambiÃ©n, hay reglas sobre como las palabras se pueden combinar, i.e., _sintaxis y gramÃ¡tica_\n",
    "\n",
    "Sin embargo, es un problema sumamente complicado, hay muchas reglas, variantes, excepciones, errores, etc.\n",
    "\n",
    "Y por si fuera poco, aunque los conceptos existen en esencia, aparecen de manera diferente en todos los lenguajes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1c23e58d-924d-4bb0-9293-ef8f520fd240"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "AdemÃ¡s, esta el problema semÃ¡ntico:\n",
    "\n",
    "- un tÃ©rmino $s_i$ tiene significados diferentes (antÃ³nimos)\n",
    "- lo contrario tambiÃ©n existe, $s_i \\not= s_j$ pero que son idÃ©nticos en significado (sinÃ³nimos)\n",
    "- en ambos casos, el significado preciso depende del contexto\n",
    "- tambiÃ©n hay casos _aproximados_ de todo lo anterior\n",
    "- hay muchÃ­simos problemas abiertos\n",
    "\n",
    " **NLP** es complicado, de hecho es _AI-complete_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "76b4afb4-0abd-4f1d-a167-3d1f9abadbf5"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nuestro Enfoque #\n",
    "Por su complejidad, trabajar en NLP tiene una gran cantidad de problemas abiertos, en particular nosotros nos enfocamos en la clasificaciÃ³n de texto escrito de manera informal (e.g., Twitter).\n",
    "\n",
    "Para esto se utiliza un _pipeline_ estÃ¡ndar\n",
    "\n",
    "![Pipeline](fig-pipeline.png)\n",
    "\n",
    "No es la Ãºnica opciÃ³n, pero fijar el pipeline es Ãºtil como ya se expondrÃ¡.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El enfoque teÃ³rico suele ser muy complicado, y en realidad poco efectivo en la prÃ¡ctica, dadas las simplificaciones necesarias para hacerlo manejable\n",
    "\n",
    "- LÃ³gica\n",
    "- LingÃ¼istica\n",
    "- SemÃ¡ntica\n",
    "\n",
    "El enfoque prÃ¡ctico supone muchas cosas, en particular es un tanto casuÃ­stico:\n",
    "    \n",
    "- Se fija el lenguaje\n",
    "- Se fija el problema\n",
    "- Y la raÃ­z de todos los males, muchas veces se supone que entre mÃ¡s tÃ©cnicas sofÃ­sticadas se usen, mejores resultados se tendrÃ¡n\n",
    "\n",
    "En ambos enfoques se suele suponer que ausencia de errores de diferentes fuentes, sin embargo, es la regla cuando el texto que se analiza fue generado por usuarios de una red social, e.g. Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8a2f28db-806c-43bf-a178-38176c300102"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Â¿QuÃ© es $\\mu TC$? #\n",
    "micro TC o $\\mu TC$ es un clasificador de texto desarrollado en\n",
    "el _Laboratorio de AnÃ¡lisis Computacional de Grandes CÃºmulos de InformaciÃ³n_\n",
    "(o _Laboratorio de BigDATA_) de INFOTEC, sede Aguascalientes.\n",
    "\n",
    "Esta disponible para ser clonado en [https://github.com/INGEOTEC/microTC](https://github.com/INGEOTEC/microTC). Esta escrito en Python 3.5 para sacar ventaja de unicode. TambiÃ©n se puede instalar utilizando `pip` y `conda`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6b172843-4297-41c3-a02c-0624b8371113"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En particular, nuestro enfoque se basa en _aprendizaje computacional_ y _optimizaciÃ³n combinatoria_. Hemos probado que este esquema es muy competitivo en la prÃ¡ctica. AdemÃ¡s, con la adecuada selecciÃ³n de las funciones podemos lograr que \n",
    "$\\mu TC$ se independiente del lenguaje y robusto a errores.\n",
    "\n",
    "Esta compuesto por:\n",
    "- una serie de funciones de transformaciÃ³n de texto\n",
    "- una serie de tokenizadores\n",
    "- filtros de palabras y\n",
    "- algoritmos de pesado de tÃ©rminos\n",
    "\n",
    "Todo esto orquestado mediante un algoritmo de optimizaciÃ³n combinatoria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entonces, $\\mu TC$ optimiza el sub-proceso **normalizaciÃ³n $\\rightarrow$ tokenizado $\\rightarrow$ pesado ** para una tarea de clasificaciÃ³n de texto dada. De manera mÃ¡s detallada, una tarea esta definida por $(D, C, f)$\n",
    "\n",
    "- $D$ es el conjunto de entrenamiento, cada elemento es un documento\n",
    "- $C$ es el conjunto de clases o etiquetas validas\n",
    " * todo $d \\in D$ tiene asociado una etiqueda $C_d \\in C$\n",
    "- $f$ es una funciÃ³n de aptitud $f: T \\rightarrow \\mathbb{R}^+$, i.e., una medida de que tan bien va la clasificaciÃ³n para un conjunto de prueba $T$\n",
    "\n",
    "El conjunto de prueba $T$ tiene la misma forma de $D$, i.e., $C_d \\in C$ para todo ${d \\in T}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "afbf9d0b-a293-4282-b281-35583ac57b2e"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lista de parametros ##\n",
    "\n",
    "### Normalizadores multilenguaje ###\n",
    "\n",
    "|   nombre  | valores             |        descripciÃ³n                   |\n",
    "|-----------|---------------------|--------------------------------------|\n",
    "|\tdel-punc | yes, no | Determina si las puntuaciones deben removerse |\n",
    "|\tdel-d1   | yes, no | Determina si se deben borrar letras repetidas |\n",
    "|\tdel-diac | yes, no | Determina si los simbolos que no ocupan espacios deben ser removidos |\n",
    "|\tlc       | yes, no | Determina si los sÃ­mbolos deben ser normalizados en minÃºsculas |\n",
    "|\temo      | remove, group, none | Controla como deben tratarse los emoticones |\n",
    "|\tnum      | remove, group, none | `........................` nÃºmeros |\n",
    "|\turl      | remove, group, none | `........................` urls |\n",
    "|\tusr      | remove, group, none | `........................` usuarios |\n",
    "\n",
    "configuraciones: 1296\n",
    "\n",
    "\n",
    "### Normalizadores dependientes del lenguaje ###\n",
    "\n",
    "|   nombre  | valores             |        descripciÃ³n                   |\n",
    "|-----------|---------------------|--------------------------------------|\n",
    "|\tstem   | yes, no | Determina si a las palabras se les aplica _stemming_. |\n",
    "|\tneg    | yes, no | Determina si los operadores de negaciÃ³n son manejados de manera especial |\n",
    "|\tsw | remove, group, none | Controla como los _stopwords_ son manejados |\n",
    "\n",
    "configuraciones: 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tokenizadores ###\n",
    "Los tokenizadores son en realidad una lista de tokenizadores, y estÃ¡n definidos tokenizer un elemento en $\\wp{(\\text{n-words} \\cup \\text{q-grams} \\cup \\text{skip-grams})} \\setminus \\{\\emptyset\\}$\n",
    "\n",
    "|   nombre  | valores             |        descripciÃ³n                   |\n",
    "|-----------|---------------------|--------------------------------------|\n",
    "|\tn-words    | $\\{1,2,3\\}$      | Longitud de n-gramas de palabras (n-words) |\n",
    "|\tq-grams  | $\\{1,2,3,4,5,6,7\\}$ | Longitud de q-gramas de caracteres) |\n",
    "|\tskip-grams  | $\\{(2,1), (3, 1), (2, 2), (3, 2)\\}$ | skip-gram list. |\n",
    "\n",
    "configuracione: 16383\n",
    "\n",
    "### Parametros para pesado ###\n",
    "|   nombre  | valores             |        descripciÃ³n                   |\n",
    "|-----------|---------------------|--------------------------------------|\n",
    "|token_min_filter | $\\{0.01, 0.03, 0.1, 0.30, -1, -5, -10\\}$ | Filtro de frequencias bajas |\n",
    "|token_max_filter | $\\{0.9, 99, 1.0\\}$ | Filtro de frequencias altas |\n",
    "|\ttfidf    | yes, no | Determina si se debe realizar un pesado TFIDF de terminos |\n",
    "\n",
    "configuraciones = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10668085344 202830.73511293635\n"
     ]
    }
   ],
   "source": [
    "conf = 42 * 16383 * 12 * 1292\n",
    "time = conf * 10 / 60 / 24 / 365.25\n",
    "print(conf, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Con esto tenemos un total de $10,668,085,344$ configuraciones. Dependiendo del tamaÃ±o de cada colecciÃ³n, cada configuraciÃ³n se evalua en tiempo diferente.\n",
    "\n",
    "Una tarea tÃ­pica de anÃ¡lisis de sentimientos tiene un costo por configuraciÃ³n de cerca de 10 min. en una computadora de relativamente nueva, i.e., Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz.\n",
    "\n",
    "Esto no da un total de $202,830.74$ aÃ±os de tiempo de cÃ³mputo.\n",
    "\n",
    "Un enfoque _naÃ¯ve_ requiere una cantidad enorme de computadoras para parallelizar y distribuir este proceso, por esta razÃ³n, es mejor utilizar algoritmos eficientes para optimizar la bÃºsqueda de la mejor configuraciÃ³n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OptimizaciÃ³n combinatoria #\n",
    "Para tener algo prÃ¡ctico utilizamos una aproximaciÃ³n a encontrar la configuraciÃ³n Ã³ptima (modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3f510c80-93c5-4e42-a5bf-3b0b24fd59ca"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sobre el pesado ##\n",
    "El pesado de tokens esta fijo a TFIDF. Su nombre viene de la formulaciÃ³n $tf \\times idf$\n",
    "\n",
    "$tf$ es _term frequency_; es una medida de importancia **local** del tÃ©rmino $t$ en el documento $d$, de manera normalizada esta definida como:\n",
    "    $$tf(t,d) = \\frac{freq(t, d)}{\\max_{w \\in d}{freq(w, d)}}$$\n",
    "entre mÃ¡s veces aparece en el documento $d$, $t$ es mÃ¡s importante\n",
    "\n",
    "$idf$ quiere decir _inverse document frequency_; es una medida **global** a la colecciÃ³n $D$, esta definida como:\n",
    "$$ idf(t,d) = log{\\frac{|D|}{1+|{d \\in D: t \\in d}|}} $$\n",
    "entre mÃ¡s veces aparece $t$ en la colecciÃ³n, el tÃ©rmino es mÃ¡s comÃºn y menos discriminante; por lo tanto, menos importante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0cedcc81-a913-4453-81aa-3386a4bbc972"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sobre el clasificador ##\n",
    "El clasificador es un algoritmo de aprendizaje computacional que dado un objeto, decide finalmente la etiqueta o clase de ese objeto. Tiene dos etapas bien definidas\n",
    "\n",
    "- **Entrenamiento.** Dado un conjunto de ejemplos en un espacio vectorial, con etiquetas, el algoritmo intenta _aprender_ las caracterÃ­sticas que definen cada clase\n",
    "- **PredicciÃ³n.** La idea es que una vez entrenado, el algoritmo puede recibir objetos no vistos durante la etapa de entrenamiento y asignales la clase adecuada\n",
    "\n",
    "En particular, esta fijo como un _Support Vector Machine_ (SVM) con kernel lineal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b9e49694-b1e2-47b7-a6ee-c118b8dccf41"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = \"anita lava la tina\"\n",
    "tokenizers = [1, 2, 3, -1, -2, (2,1), (2,2)]\n",
    "\n",
    "num = 1\n",
    "output = []\n",
    "for ltokens in range(len(tokenizers)):\n",
    "    output.append('## Combinaciones de tamaÃ±o {0} ##'.format(ltokens+1))\n",
    "    output.append('|id|combinaciÃ³n|tokens|')\n",
    "    output.append('|--|-----------|------|')\n",
    "    for comb in combinations(tokenizers, ltokens+1):\n",
    "        model = TextModel([], token_list=comb)\n",
    "        output.append(\"|{0}|{1}|{2}|\".format(num, comb, \", \".join(model.tokenize(text))))\n",
    "        num += 1\n",
    "\n",
    "Markdown(\"\\n\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5702f691-7640-40a3-bd02-1c337dfb6686"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Emoticones y emojis clasificados por sentimiento ##\n",
       "## Clase `NONE` ##\n",
       "'~'U  ^( \\\\\\'-\\\\\\' )^  Ï€  ÏŸ  à² ~à²   â€·Ì—â†‚å‡¸â†‚â€´  â€¼  â‚  â‰  â  â‘  â„¹  â†¶  â†·  âˆ¨  âˆ©  âˆª  âˆ´  âŠ•  âŠ—  âŠš  âŠ›  âŠœ  âŠ¥  âŒ†  âŒ˜  âŒ¥  âŒ«  âˆ  â‹  âŒ  â  â  â•½  â•¿  â—‰  â—  â—  â—‘  â—’  â—“  â—”  â—•  â—–  â——  â˜„  â˜‡  â˜ˆ  â˜‰  â˜Š  â˜Œ  â˜  â˜  â˜  â˜›  â˜  â˜  â˜¤  â˜§  â˜¨  â˜©  â˜ª  â˜«  â˜¬  â˜­  â˜¸  â˜¿  â™Š  â™‹  â™Œ  â™  â™  â™  â™  â™‘  â™’  â™“  â™¤  â™¨  â™­  â™®  â™¯  â™¿  âš’  âš“  âš”  âš•  âš˜  âšš  âšœ  âšª  âš«  âœ†  âœ‡  âœŠ  âœ‘  âœ   âœ¡  âœ¢  âœ£  âœ¤  âœ¥  âœ¦  âœ§  â–  â—  â¦  â§  â–  â—  â°  â·  âº  â¿  ã¥  ã‚  ã‚¬  ã‚®  ã‚°  ã‚²  ã‚´  ã‚¶  ã‚º  ã‚¼  ãƒ  ãƒ“  ãƒ·  ãƒ¹  ãƒº  ãŠŠ  ãŠ‹  ãŠŒ  ãŠ  ãŠ  ãŠ  ãŠ  ìœ   ï¹¢  ï¹£  ï¹¤  ï¹¥  ğŸ€„...\n",
       "## Clase `POS` ##\n",
       "(^L^)  (^â€¿^)  (Â°âŒ£Â°)  (â€¢â€¿â€¢)  (ï½¡â—•â€¿â—•ï½¡)  *-*  :)  :*  :-)  :-*  :-D  :3  :B  :D  :]  :p  ;)  ;-)  ;D  < (^^,) >  <3  <ã€â˜¯ã€‘â€¿ã€â˜¯ã€‘>  =)  =D  =^.^=  D:  Dx  XP  ^( \\\\\\'â€¿\\\\\\' )^  ^.^  ^^  ^_^  ^o^  ^â€¿^  n_n  q(â‚â€¿â‚)p  xD  {â—• â—¡ â—•}  |â—”â—¡â—‰|  Â¢â€¿Â¢  Ãœ  Ã±.Ã±  Ã±__Ã±  Ã±_Ã±  Ã³â€¿Ã³  Øª  Ù©(-Ì®Ì®Ìƒ-Ìƒ)Û¶  Ù©(-Ì®Ì®Ìƒâ€¢Ìƒ)  Ù©(^â€¿^)Û¶  Ù©(Í¡à¹Ì®Í¡à¹)Û¶  Ù©â—”â€¿â—”Û¶  à² â—¡à²   à¼ºâ€¿à¼»  áƒ¦  áµ”á´¥áµ”  â€ğŸ‘¨â¤â€ï¸â€ğŸ’‹ğŸ‘¨  â€ğŸ‘©â¤â€ï¸â€ğŸ’‹ğŸ‘¨  â€ğŸ‘©â¤â€ï¸â€ğŸ’‹ğŸ‘©  â€   â‡§  â‡ª  âˆš  â‰§â—¡â‰¦  âŠ‚â—‰â€¿â—‰ã¤  âŠ™â–ƒâŠ™  â‹†  âŸ  â”Œ(à² â€¿à² )â”˜  â•³  â—â€¿â—  â—•â€¿â—•Ù©(â—Ì®Ì®Ìƒâ€¢Ìƒ)Û¶  â—™â€¿â—™  â˜€  â˜ƒ  â˜…  â˜†  â˜‹  â˜‘  â˜•  â˜˜  â˜š  â˜œ  â˜¥  â˜¦  â˜®  â˜¯  â˜º  â˜»  â˜¼  â˜½  â˜¾  â™‰  â™”  â™•  â™–  â™š  â™›  â™¡  â™£  â™¥  â™¥â€¿â™¥  â™§  â™©  â™ª  â™«  â™¬  â™»  âš–  âš›  â›¹  â›¹ğŸ»  â›¹ğŸ¼  â›¹ğŸ½  â›¹ğŸ¾  â›¹ğŸ¿  âœ…  âœˆ  âœ‰  âœŒ  âœŒğŸ»  âœŒğŸ¼  âœŒğŸ½  âœŒğŸ¾  âœŒğŸ¿  âœ“  âœ”  âœ™  âœš  âœ›  âœœ  âœ  âœ  âœŸ  âœ¨  âœ©  âœª  âœ«  âœ¬  âœ­  âœ®  âœ¯  âœ°  âœ±  âœ²  âœ³  âœ´  âœµ  âœ¶  âœ·  âœ¸  âœ¹  âœº  âœ»  âœ¼  âœ½  âœ¾  âœ¿  â€  â€â€¿â€  â  â‚  âƒ  â‡  âˆ  â‰  âŠ  â‹  â•  â£  â¤  â¤ï¸  â¤ï¸â€¿â¤ï¸  â¥  â•  â³  âµ  â¸  â¹  â»  â¼  â½  â­  ã‚·  ã‚¸  ã‚¾  ãƒƒ  ãƒ„  ãƒ…  ã‹¡  ä¹‚â—œâ—¬â—ä¹‚  ì›ƒ  ğŸŒ„  ğŸŒ…  ğŸŒ·  ğŸŒ¹  ğŸŒº  ğŸŒ»  ğŸŒ¼  ğŸ€  ğŸ»  ğŸ¾  ğŸ‚  ğŸ„  ğŸ†  ğŸ‡  ğŸˆ  ğŸ‰  ğŸŠ  ğŸ‘  ğŸ–  ğŸŸ  ğŸ§  ğŸ«  ğŸµ  ğŸ¶  ğŸ¼  ğŸ…  ğŸ†  ğŸ©  ğŸµ  ğŸ­  ğŸ®  ğŸ±  ğŸµ  ğŸ‘‹  ğŸ‘‹ğŸ»  ğŸ‘‹ğŸ¼  ğŸ‘‹ğŸ½  ğŸ‘‹ğŸ¾  ğŸ‘‹ğŸ¿  ğŸ‘Œ  ğŸ‘ŒğŸ»  ğŸ‘ŒğŸ¼  ğŸ‘ŒğŸ½  ğŸ‘ŒğŸ¾  ğŸ‘ŒğŸ¿  ğŸ‘  ğŸ‘ğŸ»  ğŸ‘ğŸ¼  ğŸ‘ğŸ½  ğŸ‘ğŸ¾  ğŸ‘ğŸ¿  ğŸ‘  ğŸ‘ğŸ»  ğŸ‘ğŸ¼  ğŸ‘ğŸ½  ğŸ‘ğŸ¾  ğŸ‘ğŸ¿  ğŸ‘...\n",
       "## Clase `NEG` ##\n",
       "'n'  (>.<)  (O.O)  (âŠ™Ìƒ.o âŠ™.â—)  )-:  ):  ):-/  .l.  /:  :\"(  :'(  :(  :-(  :-/  :-\\  :-o  :-x  :/  :S  :[  :\\  :c  :o  ='(  =(  =S  >.<  >:-(  >:o  ><  >_<  O.o  O.Ã³  TT  XC  X_X  \\\\\\\\m/(>.<)\\\\\\\\m/  o.Ã“  oÌƒ.O  x_x  Â¬ Â¬  Â¬ Â¬*  Â¬Â¬*  Â».Â«  Ã²_Ã³  à¥“_à¥”  à¹_à¹  âŠ  âŒ›  âŒ¤  â˜‚  â˜’  â˜”  â˜Ÿ  â˜   â˜¢  â˜£  â˜¹  âš   âš¡  â›”  âœ‚  âœŠğŸ»  âœŠğŸ¼  âœŠğŸ½  âœŠğŸ¾  âœŠğŸ¿  âœ‹  âœ•  âœ–  âœ—  âœ˜  âŒ  â  ã€´â‹‹_â‹Œã€µ  å  å  ğŸŒ  ğŸ—  ğŸ‘¹  ğŸ‘º  ğŸ‘»  ğŸ‘½  ğŸ‘¾  ğŸ‘¿  ğŸ’€  ğŸ’”  ğŸ’¢  ğŸ’£  ğŸ’¦  ğŸ’¨  ğŸ’©  ğŸ’«  ğŸ“‰  ğŸ–•  ğŸ–•ğŸ»  ğŸ–•ğŸ¼  ğŸ–•ğŸ½  ğŸ–•ğŸ¾  ğŸ–•ğŸ¿  ğŸ—¯  ğŸ˜“  ğŸ˜”  ğŸ˜–  ğŸ˜  ğŸ˜Ÿ  ğŸ˜   ğŸ˜¡  ğŸ˜¢  ğŸ˜£  ğŸ˜¥  ğŸ˜¦  ğŸ˜§  ğŸ˜¨  ğŸ˜©  ğŸ˜ª  ğŸ˜«  ğŸ˜¬  ğŸ˜­  ğŸ˜®  ğŸ˜¯  ğŸ˜°  ğŸ˜±  ğŸ˜²  ğŸ˜³  ğŸ˜µ  ğŸ˜·  ğŸ˜¾  ğŸ˜¿  ğŸ™€  ğŸ™  ğŸ™ƒ  ğŸ™…  ğŸ™…ğŸ»  ğŸ™…ğŸ¼  ğŸ™…ğŸ½  ğŸ™…ğŸ¾  ğŸ™…ğŸ¿  ğŸ™ˆ  ğŸ™‰  ğŸ™Š  ğŸ™  ğŸ™ğŸ»  ğŸ™ğŸ¼  ğŸ™ğŸ½  ğŸ™ğŸ¾  ğŸ™ğŸ¿  ğŸš«  ğŸš³  ğŸ¤’  ğŸ¤•  ğŸ¤˜  ğŸ¤˜ğŸ»  ğŸ¤˜ğŸ¼  ğŸ¤˜ğŸ½  ğŸ¤˜ğŸ¾  ğŸ¤˜ğŸ¿...\n",
       "## Clase `NEU` ##\n",
       "#âƒ£  $_$  &  (-\\\\\\'\\\\\\'-)  (â€¢Ìªâ—)  *âƒ£  -.-  -_-  ._.  0âƒ£  1âƒ£  2âƒ£  3âƒ£  4âƒ£  5âƒ£  6âƒ£  7âƒ£  8-|  8âƒ£  9âƒ£  :-|  >:-o  @_@  U_U  n__n  u.u  u_u  v( â€˜.â€™ )v  {â€¢ÌƒÌ¾_â€¢ÌƒÌ¾}  |Ëšâ€“Ëš|  Â©  Â¬Â¬  Â®  à° _à°   à²°_à²°  â€ğŸ‘¨â¤â€ï¸ğŸ‘¨  â€ğŸ‘©â¤â€ï¸ğŸ‘¨  â€ğŸ‘©â¤â€ï¸ğŸ‘©  â„¢  â†”  â†•  â†–  â†—  â†˜  â†™  â†©  â†ª  â‡_â‡  âŒš  âŒ¨  â©  âª  â«  â¬  â­  â®  â¯  â°  â±  â²  â³  â¸  â¹  âº  â“‚  â–ª  â–«  â–¶  â—€  â—.Ìƒâ—  â—‘.â—‘  â—”_â—”  â—»  â—¼  â—½  â—¾  â˜  â˜ğŸ»  â˜ğŸ¼  â˜ğŸ½  â˜ğŸ¾  â˜ğŸ¿  â™€  â™  â™‚  â™ˆ  â™—  â™˜  â™™  â™œ  â™  â™  â™Ÿ  â™   â™¢  â™¦  âš—  âš™  âš°  âš±  âš½  âš¾  â›„  â›…  â›ˆ  â›  â›  â›‘  â›“  â›©  â›ª  â›°  â›±  â›²  â›³  â›´  â›µ  â›·  â›¸  â›º  â›½  âœ‹ğŸ»  âœ‹ğŸ¼  âœ‹ğŸ½  âœ‹ğŸ¾  âœ‹ğŸ¿  âœ  âœğŸ»  âœğŸ¼  âœğŸ½  âœğŸ¾  âœğŸ¿  âœ  âœ  âœ’  â„  â…  â†  â“  â”  â¡  â¤´  â¤µ  â¬…  â¬†  â¬‡  â¬›  â¬œ  â­•  ã€â€¢ã€‘_ã€â€¢ã€‘  ã€°  ã€½  ãŠ—  ãŠ™  ğŸƒ  ğŸ…°  ğŸ…±  ğŸ…¾  ğŸ…¿  ğŸ†  ğŸ†‘  ğŸ†’  ğŸ†“  ğŸ†”  ğŸ†•  ğŸ†–  ğŸ†—  ğŸ†˜  ğŸ†™  ğŸ†š  ğŸ‡¦ğŸ‡¨  ğŸ‡¦ğŸ‡©  ğŸ‡¦ğŸ‡ª  ğŸ‡¦ğŸ‡«  ğŸ‡¦ğŸ‡¬  ğŸ‡¦ğŸ‡®  ğŸ‡¦ğŸ‡±  ğŸ‡¦ğŸ‡²  ğŸ‡¦ğŸ‡´  ğŸ‡¦ğŸ‡¶  ğŸ‡¦ğŸ‡·  ğŸ‡¦ğŸ‡¸  ğŸ‡¦ğŸ‡¹  ğŸ‡¦ğŸ‡º  ğŸ‡¦ğŸ‡¼  ğŸ‡¦ğŸ‡½  ğŸ‡¦ğŸ‡¿  ğŸ‡§ğŸ‡¦  ğŸ‡§ğŸ‡§  ğŸ‡§ğŸ‡©  ğŸ‡§ğŸ‡ª  ğŸ‡§ğŸ‡«  ğŸ‡§ğŸ‡¬  ğŸ‡§ğŸ‡­  ğŸ‡§ğŸ‡®  ğŸ‡§ğŸ‡¯  ğŸ‡§ğŸ‡±  ğŸ‡§ğŸ‡²  ğŸ‡§ğŸ‡³  ğŸ‡§ğŸ‡´  ğŸ‡§ğŸ‡¶  ğŸ‡§ğŸ‡·  ğŸ‡§ğŸ‡¸  ğŸ‡§ğŸ‡¹  ğŸ‡§ğŸ‡»  ğŸ‡§ğŸ‡¼  ğŸ‡§ğŸ‡¾  ğŸ‡§ğŸ‡¿  ğŸ‡¨ğŸ‡¦  ğŸ‡¨ğŸ‡¨  ğŸ‡¨ğŸ‡©  ğŸ‡¨ğŸ‡«  ğŸ‡¨ğŸ‡¬  ğŸ‡¨ğŸ‡­  ğŸ‡¨ğŸ‡®  ğŸ‡¨ğŸ‡°  ğŸ‡¨ğŸ‡±  ğŸ‡¨ğŸ‡²  ğŸ‡¨ğŸ‡³  ğŸ‡¨ğŸ‡´  ğŸ‡¨ğŸ‡µ  ğŸ‡¨ğŸ‡·  ğŸ‡¨ğŸ‡º  ğŸ‡¨ğŸ‡»  ğŸ‡¨ğŸ‡¼  ğŸ‡¨ğŸ‡½  ğŸ‡¨ğŸ‡¾  ğŸ‡¨ğŸ‡¿  ğŸ‡©ğŸ‡ª  ğŸ‡©ğŸ‡¬  ğŸ‡©ğŸ‡¯  ğŸ‡©ğŸ‡°  ğŸ‡©ğŸ‡²  ğŸ‡©ğŸ‡´  ğŸ‡©ğŸ‡¿  ğŸ‡ªğŸ‡¦  ğŸ‡ªğŸ‡¨  ğŸ‡ªğŸ‡ª  ğŸ‡ªğŸ‡¬  ğŸ‡ªğŸ‡­  ğŸ‡ªğŸ‡·  ğŸ‡ªğŸ‡¸  ğŸ‡ªğŸ‡¹  ğŸ‡ªğŸ‡º  ğŸ‡«ğŸ‡®  ğŸ‡«ğŸ‡¯  ğŸ‡«ğŸ‡°  ğŸ‡«ğŸ‡²  ğŸ‡«ğŸ‡´  ğŸ‡«ğŸ‡·  ğŸ‡¬ğŸ‡¦  ğŸ‡¬ğŸ‡§  ğŸ‡¬ğŸ‡©  ğŸ‡¬ğŸ‡ª  ğŸ‡¬ğŸ‡«  ğŸ‡¬ğŸ‡¬  ğŸ‡¬ğŸ‡­  ğŸ‡¬ğŸ‡®  ğŸ‡¬ğŸ‡±  ğŸ‡¬ğŸ‡²  ğŸ‡¬ğŸ‡³  ğŸ‡¬ğŸ‡µ ..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emoformat(A, emo):\n",
    "    s = \"  \".join([a[0] for a in A if a[1] == emo])\n",
    "    return s[:1000] + \"...\"\n",
    "    \n",
    "with open('microTC/microtc/resources/emoticons.json') as f:\n",
    "    A = list(json.load(f).items())\n",
    "    A.sort()\n",
    "    S = dict(\n",
    "        pos=emoformat(A, '_pos'),\n",
    "        neg=emoformat(A, '_neg'),\n",
    "        neu=emoformat(A, '_neu'),\n",
    "        none=emoformat(A, '_none'),\n",
    "    )\n",
    "\n",
    "output = [\"## Emoticones y emojis clasificados por sentimiento ##\"]\n",
    "for k, v in S.items():\n",
    "    output.append(\"## Clase `{0}` ##\".format(k.upper()))\n",
    "    output.append(v)\n",
    "\n",
    "Markdown(\"\\n\".join(output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "b0433df0-cf31-4f76-8bbe-2fbdab949ff3",
    "theme": {
     "b0433df0-cf31-4f76-8bbe-2fbdab949ff3": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "b0433df0-cf31-4f76-8bbe-2fbdab949ff3",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         240,
         241,
         235
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         56,
         61,
         61
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         81,
         72,
         61
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         0,
         0,
         0
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "EB Garamond",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "EB Garamond",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "EB Garamond",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "EB Garamond",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "EB Garamond"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "EB Garamond"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "EB Garamond"
       },
       "li": {
        "color": "mainColor",
        "font-family": "EB Garamond",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "EB Garamond",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "EB Garamond",
       "font-size": 5
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
